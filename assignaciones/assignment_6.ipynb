{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639be9b7",
   "metadata": {},
   "source": [
    "# Detección de Grietas en Superficies de Concreto usando Redes Neuronales (FC vs. CNN)\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En esta asignación se aborda el problema de detección de grietas en superficies de concreto utilizando imágenes RGB provenientes del dataset **Surface Crack Detection** disponible en Kaggle. Este conjunto contiene un total de 40,000 imágenes de 227x227 píxeles, balanceado entre clases positivas (grietas) y negativas (sin grietas).\n",
    "\n",
    "El objetivo principal es desarrollar, entrenar y comparar el desempeño de dos enfoques de redes neuronales:\n",
    "\n",
    "- Una red neuronal **totalmente conectada (Fully Connected - FC)**, que recibe imágenes aplanadas como vectores de entrada.\n",
    "- Una red **convolucional (CNN)**, diseñada específicamente para tareas de visión por computadora, capaz de aprender representaciones espaciales jerárquicas.\n",
    "\n",
    "Ambos modelos serán evaluados en la tarea de **clasificación binaria**, determinando si una imagen contiene o no una grieta.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Cargar y explorar el dataset Surface Crack Detection.\n",
    "- Preprocesar las imágenes, incluyendo normalización y partición en conjuntos de entrenamiento, validación y prueba.\n",
    "- Diseñar e implementar una red totalmente conectada que reciba imágenes aplanadas.\n",
    "- Diseñar e implementar una red convolucional adaptada a la estructura espacial de las imágenes.\n",
    "- Entrenar ambos modelos y graficar la evolución de la función de pérdida y la precisión durante el entrenamiento.\n",
    "- Evaluar el desempeño de cada red en el conjunto de prueba utilizando métricas como **accuracy**, **precision**, **recall** y **F1-score**.\n",
    "- Comparar y analizar los resultados obtenidos, identificando ventajas y limitaciones de cada arquitectura para esta tarea.\n",
    "\n",
    "## Importancia del problema\n",
    "\n",
    "La detección automatizada de grietas es fundamental para el mantenimiento preventivo de infraestructuras como puentes, carreteras y edificios. Métodos basados en visión por computadora ofrecen una alternativa rápida, económica y no invasiva frente a inspecciones manuales. Evaluar diferentes arquitecturas de redes neuronales en esta tarea permite identificar soluciones eficientes que puedan escalar a sistemas reales de monitoreo estructural.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e258f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Descripción del Dataset\n",
    "\n",
    "El dataset utilizado en este proyecto es el **Surface Crack Detection Dataset**, disponible públicamente en [Kaggle](https://www.kaggle.com/datasets/arunrk7/surface-crack-detection). Este conjunto de datos fue diseñado para entrenar modelos de clasificación binaria que determinen la presencia o ausencia de grietas en superficies de concreto.\n",
    "\n",
    "### Características del Dataset\n",
    "\n",
    "- **Total de imágenes:** 40,000  \n",
    "- **Clases:**  \n",
    "  - `Positive` (1): imagen contiene una grieta  \n",
    "  - `Negative` (0): imagen sin grietas  \n",
    "- **Tamaño de las imágenes:** 227×227 píxeles  \n",
    "- **Canales:** 3 (RGB)  \n",
    "- **Formato:** JPG  \n",
    "- **Distribución balanceada:** 20,000 imágenes por clase\n",
    "\n",
    "### Estructura del Dataset\n",
    "\n",
    "El dataset está organizado en dos carpetas principales:\n",
    "\n",
    "```\n",
    "Surface_Crack_Detection/\n",
    "├── Positive/   # Imágenes con grietas (20,000)\n",
    "└── Negative/   # Imágenes sin grietas (20,000)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Origen de los datos\n",
    "\n",
    "Las imágenes fueron generadas a partir de 458 imágenes reales de superficies de concreto, recolectadas en diferentes condiciones de iluminación y textura. Posteriormente se aplicaron técnicas de segmentación y recorte para crear imágenes individuales de alta resolución. El dataset fue diseñado para facilitar tareas de clasificación, detección y segmentación de defectos estructurales.\n",
    "\n",
    "### Consideraciones\n",
    "\n",
    "- El tamaño uniforme de las imágenes (227x227) facilita su uso directo en redes convolucionales sin necesidad de redimensionamiento adicional.\n",
    "- Aunque el dataset incluye variabilidad en texturas y condiciones visuales, no contiene etiquetas de localización (como bounding boxes o máscaras), por lo que se usa principalmente para **clasificación binaria**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb88350",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Paso 1: Cargar y explorar el dataset\n",
    "\n",
    "- Descargar y descomprimir el dataset desde Kaggle.\n",
    "- Verificar la estructura de carpetas:\n",
    "\n",
    "```\n",
    "Surface_Crack_Detection/\n",
    "├── Positive/ # Imágenes con grietas\n",
    "└── Negative/ # Imágenes sin grietas\n",
    "```\n",
    "\n",
    "- Contar el número total de imágenes por clase.\n",
    "- Visualizar algunas muestras de ambas clases para entender el tipo de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cf98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0339f",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 2: Preprocesamiento y partición del dataset\n",
    "\n",
    "- Asignar etiqueta `1` a las imágenes de `Positive` y `0` a las de `Negative`.\n",
    "- Cargar las imágenes con tamaño fijo (227×227), redimensionarlas y convertirlas a tensores (PyTorch) o arrays (TensorFlow).\n",
    "- Normalizar los valores de píxeles al rango [0, 1].\n",
    "\n",
    "#### Esquema de partición:\n",
    "\n",
    "1. Reservar **20 % del total** como conjunto de prueba final (`test`), que **no se toca durante el entrenamiento ni validación**.\n",
    "2. Del 80 % restante (conjunto de desarrollo), separar:\n",
    "   - **80 % para entrenamiento** → 64 % del total\n",
    "   - **20 % para validación** → 16 % del total\n",
    "\n",
    "#### Resumen de proporciones:\n",
    "\n",
    "| Conjunto     | Porcentaje del total | Uso                                 |\n",
    "|--------------|----------------------|--------------------------------------|\n",
    "| Entrenamiento| 64 %                 | Entrenar los modelos                 |\n",
    "| Validación   | 16 %                 | Ajustar hiperparámetros y arquitectura |\n",
    "| Prueba       | 20 %                 | Evaluación final del rendimiento     |\n",
    "\n",
    "#### Consideraciones adicionales:\n",
    "\n",
    "- La división debe ser **estratificada** para conservar el balance entre clases en cada subconjunto.\n",
    "- Aplicar **data augmentation solo al conjunto de entrenamiento**:\n",
    "  - Rotaciones aleatorias\n",
    "  - Flips horizontales\n",
    "  - Zoom y desplazamientos leves\n",
    "- Validar que no haya **fugas de datos** entre los subconjuntos (por ejemplo, imágenes duplicadas en entrenamiento y prueba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48843e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd3310",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 3: Definir la red neuronal totalmente conectada (FC)\n",
    "\n",
    "En este paso se implementa una red neuronal completamente conectada (Fully Connected - FC), la cual recibe imágenes aplanadas como vectores unidimensionales y predice si la imagen contiene una grieta o no.\n",
    "\n",
    "### Arquitectura propuesta: Red neuronal totalmente conectada (FC) con 2 salidas (clasificación multiclase)\n",
    "\n",
    "#### Entrada\n",
    "- Dimensión de entrada: **3 × 227 × 227 = 154,587**\n",
    "- Las imágenes RGB se aplanan en un vector para ser procesadas por capas lineales\n",
    "\n",
    "#### Estructura de la red\n",
    "1. **Capa Lineal 1:** 154,587 → 1024\n",
    "2. **Función de activación:** ReLU\n",
    "3. **Capa Lineal 2:** 1024 → 512\n",
    "4. **Función de activación:** ReLU\n",
    "5. **Capa Lineal 3:** 512 → 128\n",
    "6. **Función de activación:** ReLU\n",
    "7. **Capa Lineal de salida:** 128 → 2  \n",
    "   - Cada unidad de salida representa una clase:\n",
    "     - `Clase 0`: sin grieta\n",
    "     - `Clase 1`: con grieta\n",
    "\n",
    "#### Función de pérdida\n",
    "- **`CrossEntropyLoss`**  \n",
    "  - Esta función aplica `softmax` internamente\n",
    "  - Las etiquetas deben ser enteros (`0` o `1`), **no one-hot encoded**\n",
    "\n",
    "#### Optimizador\n",
    "- **Adam**\n",
    "  - Tasa de aprendizaje: **0.001**\n",
    "  - Parámetros por defecto: `betas=(0.9, 0.999)`, `eps=1e-08`\n",
    "\n",
    "#### Configuración de entrenamiento\n",
    "- **Número de épocas:** 25\n",
    "- **Tamaño de batch:** 32\n",
    "- **Métricas de evaluación:** Accuracy, Precision, Recall, F1-score (macro y por clase), ROC-AUC, Tiempo de entrenamiento, Tiempo de Inferencia, Gráfico de Training Loss and Validation Loss vs Epochs.\n",
    "\n",
    "#### Notas\n",
    "- Al usar dos salidas y `CrossEntropyLoss`, se está formalizando el problema como clasificación multiclase, aunque haya solo dos clases.\n",
    "- Esto permite extender fácilmente a problemas con más categorías en el futuro si se desea.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa722fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481152bd",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 4: Definir la red neuronal convolucional (CNN)\n",
    "\n",
    "En este paso se implementa una red neuronal convolucional (Convolutional Neural Network - CNN), diseñada específicamente para capturar patrones espaciales en imágenes, como bordes, texturas y formas locales. A diferencia de la red FC, esta arquitectura mantiene la estructura espacial de las imágenes RGB y aprovecha las propiedades de las convoluciones para mejorar el aprendizaje.\n",
    "\n",
    "### Arquitectura propuesta: CNN con 2 salidas (clasificación multiclase)\n",
    "\n",
    "#### Entrada\n",
    "- Dimensión de entrada: **3 × 227 × 227**\n",
    "- Las imágenes RGB se procesan conservando su estructura espacial y canal de color\n",
    "\n",
    "#### Estructura de la red\n",
    "1. **Capa Convolucional 1:** 3 canales → 32 filtros, tamaño de kernel 3×3, padding 1\n",
    "2. **Función de activación:** ReLU\n",
    "3. **MaxPooling:** 2×2\n",
    "4. **Capa Convolucional 2:** 32 → 64 filtros, tamaño 3×3, padding 1\n",
    "5. **Función de activación:** ReLU\n",
    "6. **MaxPooling:** 2×2\n",
    "7. **Capa Convolucional 3:** 64 → 128 filtros, tamaño 3×3, padding 1\n",
    "8. **Función de activación:** ReLU\n",
    "9. **MaxPooling:** 2×2\n",
    "10. **Flatten:** la salida convolucional se convierte en un vector\n",
    "11. **Capa Lineal 1:** salida → 128 unidades\n",
    "12. **Función de activación:** ReLU\n",
    "13. **Capa Lineal de salida:** 128 → 2  \n",
    "    - Cada unidad representa una clase:\n",
    "      - `Clase 0`: sin grieta  \n",
    "      - `Clase 1`: con grieta\n",
    "\n",
    "#### Función de pérdida\n",
    "- **`CrossEntropyLoss`**\n",
    "  - Incluye la activación `softmax` internamente\n",
    "  - Las etiquetas deben estar codificadas como enteros (`0` o `1`), no en formato one-hot\n",
    "\n",
    "#### Optimizador\n",
    "- **Adam**\n",
    "  - Tasa de aprendizaje: **0.001**\n",
    "  - Parámetros por defecto: `betas=(0.9, 0.999)`, `eps=1e-08`\n",
    "\n",
    "#### Configuración de entrenamiento\n",
    "- **Número de épocas:** 25\n",
    "- **Tamaño de batch:** 32\n",
    "- **Métricas de evaluación:** Accuracy, Precision, Recall, F1-score (macro y por clase), ROC-AUC, Tiempo de entrenamiento, Tiempo de Inferencia, Gráfico de Training Loss and Validation Loss vs Epochs. \n",
    "\n",
    "#### Notas\n",
    "- La CNN es capaz de extraer características visuales jerárquicas directamente de las imágenes, lo cual suele mejorar la capacidad de generalización.\n",
    "- Esta red puede extenderse fácilmente agregando más capas convolucionales, dropout o batch normalization si se desea mejorar el rendimiento o controlar el sobreajuste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc626b7",
   "metadata": {},
   "source": [
    "---\n",
    "### Paso 5: Tabla resumen de resultados por arquitectura\n",
    "\n",
    "Una vez entrenados y evaluados ambos modelos (la red totalmente conectada y la red convolucional), construye una **tabla comparativa de resultados** que resuma el desempeño de cada arquitectura en el conjunto de prueba.\n",
    "\n",
    "#### Métricas a reportar:\n",
    "\n",
    "- **Accuracy**\n",
    "- **Precision (macro y por clase)**\n",
    "- **Recall (macro y por clase)**\n",
    "- **F1-score (macro y por clase)**\n",
    "- **ROC-AUC**\n",
    "- **Tiempo total de entrenamiento** (en segundos)\n",
    "- **Tiempo promedio de inferencia por imagen** (en milisegundos)\n",
    "- **Gráfico de Training Loss y Validation Loss vs. Epochs**\n",
    "\n",
    "#### Formato sugerido:\n",
    "\n",
    "| Modelo         | Accuracy | Precision (macro) | Recall (macro) | F1-score (macro) | ROC-AUC | Entrenamiento (s) | Inferencia (ms) |\n",
    "|----------------|----------|-------------------|----------------|------------------|---------|--------------------|------------------|\n",
    "| FC             | 0.XXX    | 0.XXX             | 0.XXX          | 0.XXX            | 0.XXX   | XXX                | X.XX             |\n",
    "| CNN            | 0.XXX    | 0.XXX             | 0.XXX          | 0.XXX            | 0.XXX   | XXX                | X.XX             |\n",
    "\n",
    "> Acompaña esta tabla con un gráfico que muestre la evolución de la pérdida durante las 25 épocas de entrenamiento:\n",
    "> - Training Loss vs Epoch\n",
    "> - Validation Loss vs Epoch\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb482c",
   "metadata": {},
   "source": [
    "\n",
    "### Paso 6: Preguntas de análisis\n",
    "\n",
    "Con base en los resultados obtenidos, responde de forma clara y justificada las siguientes preguntas:\n",
    "\n",
    "1. **¿Cuál modelo obtuvo mejor rendimiento general?**  \n",
    "   Considera todas las métricas relevantes y argumenta tu respuesta.\n",
    "\n",
    "2. **¿Qué diferencias observaste entre el comportamiento de la red FC y la CNN en cuanto a overfitting o estabilidad durante el entrenamiento?**\n",
    "\n",
    "3. **¿El tiempo de entrenamiento y la inferencia justifican el uso de una arquitectura más compleja como la CNN en este problema?**\n",
    "\n",
    "4. **¿Qué métrica consideras más importante en este contexto y por qué?**  \n",
    "   Por ejemplo, en una aplicación real, ¿te preocupa más evitar falsos negativos o falsos positivos?\n",
    "\n",
    "5. **Si tuvieras que mejorar aún más el modelo CNN, ¿qué cambios introducirías en la arquitectura o en el proceso de entrenamiento y por qué?**  \n",
    "   (regularización, dropout, batch normalization, más datos, fine-tuning con modelos preentrenados, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c8685",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación del proyecto\n",
    "\n",
    "El proyecto se compone de seis pasos estructurados. A continuación se detallan los puntos asignados a cada sección, así como el puntaje total:\n",
    "\n",
    "| Sección                                                                 | Puntos |\n",
    "|------------------------------------------------------------------------|--------|\n",
    "| **Paso 1:** Cargar y explorar el dataset                               | 5      |\n",
    "| **Paso 2:** Preprocesamiento y partición del dataset                   | 5      |\n",
    "| **Paso 3:** Red neuronal totalmente conectada (FC)                     | 60     |\n",
    "| **Paso 4:** Red neuronal convolucional (CNN)                           | 60     |\n",
    "| **Paso 5:** Tabla resumen de resultados y visualización de métricas   | 10     |\n",
    "| **Paso 6:** Preguntas de análisis y reflexión                          | 20     |\n",
    "| **Total**                                                              | **160** |\n",
    "\n",
    "---\n",
    "\n",
    "**Nota:** Para obtener la máxima puntuación se requiere justificar adecuadamente cada decisión de diseño, mantener buena organización en el notebook, utilizar visualizaciones apropiadas, y presentar resultados bien interpretados.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
